from __future__ import annotations

import asyncio
import json
import logging
import os
import re
import sqlite3
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional


log = logging.getLogger("telegram-signal-pipeline")


TOKEN_PATTERN = re.compile(r"\$?[A-Za-z]{2,10}")
DEFAULT_EXPORT_ROOT = Path(__file__).resolve().parent / "telegram_exports"


@dataclass
class TelegramMessage:
    channel: str
    message_id: int
    text: str
    timestamp: Optional[float] = None
    source_type: str = "channel"


@dataclass
class SignalPrediction:
    token: str
    stance: str  # "buy" | "sell" | "hold"
    confidence: float
    sentiment_score: float
    source: str
    source_type: str
    reason: str = ""
    message_excerpt: str = ""
    weight: float = 1.0


@dataclass
class SignalFeedback:
    source_type: str
    realized_pnl: float
    notional: float = 1.0


class TelegramScraperAdapter:
    """
    Thin wrapper around the unnohwn/telegram-scraper outputs.

    It prefers pre-scraped exports (JSON/CSV/SQLite) generated by the upstream
    repo, and falls back to a light Telethon fetch if credentials are present.
    """

    def __init__(
        self,
        export_root: Path | str | None = None,
        api_id: Optional[int] = None,
        api_hash: Optional[str] = None,
        session_name: str = "polyo_telegram",
    ):
        self.export_root = Path(export_root or DEFAULT_EXPORT_ROOT)
        self.api_id = api_id or os.getenv("TELEGRAM_API_ID")
        self.api_hash = api_hash or os.getenv("TELEGRAM_API_HASH")
        self.session_name = session_name
        self._telethon_client_cls = None
        self._telethon_string_session = os.getenv("TELEGRAM_SESSION")
        self._ensure_telethon()

    def _ensure_telethon(self) -> None:
        try:
            from telethon import TelegramClient  # type: ignore
            from telethon.sessions import StringSession  # type: ignore

            self._telethon_client_cls = (TelegramClient, StringSession)
        except Exception as exc:  # noqa: BLE001
            log.debug("Telethon unavailable (%s); live scraping disabled.", exc)
            self._telethon_client_cls = None

    def fetch_messages(self, channels: Iterable[str], limit: int = 200) -> List[TelegramMessage]:
        messages: List[TelegramMessage] = []
        for channel in channels:
            channel = channel.strip()
            if not channel:
                continue
            loaded = self._load_from_exports(channel, limit)
            if loaded:
                messages.extend(loaded)
                continue
            live = self._fetch_live(channel, limit)
            if live:
                messages.extend(live)
        return messages

    def _load_from_exports(self, channel: str, limit: int) -> List[TelegramMessage]:
        root = self.export_root / channel
        json_path = root / f"{channel}.json"
        csv_path = root / f"{channel}.csv"
        db_path = root / f"{channel}.db"

        if json_path.exists():
            try:
                data = json.loads(json_path.read_text(encoding="utf-8"))
            except Exception as exc:  # noqa: BLE001
                log.warning("Failed to parse JSON export for %s (%s)", channel, exc)
                data = []
            return self._convert_records(channel, data[:limit])

        if csv_path.exists():
            import csv

            rows: List[Dict[str, Any]] = []
            try:
                with csv_path.open("r", encoding="utf-8", newline="") as f:
                    reader = csv.DictReader(f)
                    for idx, row in enumerate(reader):
                        rows.append(row)
                        if idx + 1 >= limit:
                            break
            except Exception as exc:  # noqa: BLE001
                log.warning("Failed to parse CSV export for %s (%s)", channel, exc)
            return self._convert_records(channel, rows)

        if db_path.exists():
            try:
                conn = sqlite3.connect(db_path)
                cur = conn.cursor()
                cur.execute("SELECT message_id, date, message FROM messages ORDER BY date DESC LIMIT ?", (limit,))
                rows = cur.fetchall()
                conn.close()
                return [
                    TelegramMessage(
                        channel=channel,
                        message_id=int(r[0]),
                        text=str(r[2] or ""),
                        timestamp=self._parse_timestamp(r[1]),
                        source_type="channel",
                    )
                    for r in rows
                ]
            except Exception as exc:  # noqa: BLE001
                log.warning("Failed to read SQLite export for %s (%s)", channel, exc)
        return []

    def _parse_timestamp(self, ts: Any) -> Optional[float]:
        if ts is None:
            return None
        try:
            return float(time.mktime(time.strptime(str(ts), "%Y-%m-%d %H:%M:%S")))
        except Exception:
            try:
                return float(ts)
            except Exception:
                return None

    def _convert_records(self, channel: str, records: Iterable[Dict[str, Any]]) -> List[TelegramMessage]:
        messages: List[TelegramMessage] = []
        for rec in records:
            text = str(rec.get("message") or rec.get("text") or "")
            msg_id = int(rec.get("message_id") or rec.get("id") or len(messages))
            ts_raw = rec.get("date") or rec.get("timestamp")
            messages.append(
                TelegramMessage(
                    channel=channel,
                    message_id=msg_id,
                    text=text,
                    timestamp=self._parse_timestamp(ts_raw),
                    source_type="channel",
                )
            )
            if len(messages) >= len(records):
                break
        return messages[: len(records)]

    def _fetch_live(self, channel: str, limit: int) -> List[TelegramMessage]:
        if not self._telethon_client_cls or not self.api_id or not self.api_hash:
            return []
        TelegramClient, StringSession = self._telethon_client_cls
        session = StringSession(self._telethon_string_session) if self._telethon_string_session else self.session_name

        async def _runner() -> List[TelegramMessage]:
            msgs: List[TelegramMessage] = []
            try:
                async with TelegramClient(session, int(self.api_id), str(self.api_hash)) as client:  # type: ignore[arg-type]
                    async for message in client.iter_messages(channel, limit=limit):
                        msgs.append(
                            TelegramMessage(
                                channel=channel,
                                message_id=int(message.id),
                                text=str(message.message or ""),
                                timestamp=float(message.date.timestamp()) if getattr(message, "date", None) else None,
                                source_type="channel",
                            )
                        )
            except Exception as exc:  # noqa: BLE001
                log.warning("Live fetch failed for %s (%s)", channel, exc)
            return msgs

        try:
            return asyncio.run(_runner())
        except RuntimeError:
            return asyncio.get_event_loop().run_until_complete(_runner())  # type: ignore[call-arg]


class OpenAISentimentClient:
    """Wrapper around the OpenAI Chat Completions API for structured sentiment."""

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model
        self._client = None
        self._init_client()

    def _init_client(self) -> None:
        if not self.api_key:
            log.info("OPENAI_API_KEY missing; falling back to heuristic sentiment.")
            return
        try:
            from openai import OpenAI  # type: ignore

            self._client = OpenAI(api_key=self.api_key)
        except Exception as exc:  # noqa: BLE001
            log.warning("Failed to init OpenAI client (%s); using heuristic sentiment.", exc)
            self._client = None

    def analyze(self, message: TelegramMessage) -> List[SignalPrediction]:
        if not message.text.strip():
            return []
        model_signals = self._call_openai(message)
        if model_signals:
            return model_signals
        return self._heuristic_signals(message)

    def _heuristic_signals(self, message: TelegramMessage) -> List[SignalPrediction]:
        tokens = self._extract_tokens(message.text)
        predictions: List[SignalPrediction] = []
        for tok in tokens:
            stance = "buy" if "long" in message.text.lower() or "buy" in message.text.lower() else "hold"
            predictions.append(
                SignalPrediction(
                    token=tok,
                    stance=stance,
                    confidence=0.4,
                    sentiment_score=0.25 if stance == "buy" else 0.0,
                    source=message.channel,
                    source_type=message.source_type,
                    reason="heuristic keyword match",
                    message_excerpt=message.text[:160],
                )
            )
        return predictions

    def _extract_tokens(self, text: str) -> List[str]:
        tokens = set()
        for match in TOKEN_PATTERN.findall(text):
            cleaned = match.replace("$", "")
            if cleaned.lower() in {"usd", "usdt", "usdc"}:
                continue
            if cleaned.islower():
                continue  # skip plain lowercase words like "and", "now"
            if cleaned.lower() in {"buy", "sell", "long", "short", "now", "moon", "pump", "and"}:
                continue
            tokens.add(cleaned.upper())
        return list(tokens)

    def _call_openai(self, message: TelegramMessage) -> List[SignalPrediction]:
        if not self._client:
            return []
        prompt = (
            "You are an expert crypto analyst. Extract tradable token calls from the Telegram message. "
            "Return a JSON object with a `signals` array where each element is "
            '{"token": "...", "stance": "buy|sell|hold", "confidence": 0-1, "reason": "short reason" }. '
            "Ignore noise. Only include tokens that are explicitly recommended."
        )
        try:
            resp = self._client.chat.completions.create(  # type: ignore[attr-defined]
                model=self.model,
                messages=[
                    {"role": "system", "content": prompt},
                    {
                        "role": "user",
                        "content": f"Channel: {message.channel}\nMessage:\n{message.text}",
                    },
                ],
                response_format={"type": "json_object"},
                max_tokens=400,
                temperature=0.2,
            )
            raw = resp.choices[0].message.content or "{}"  # type: ignore[index]
            data = json.loads(raw)
            signals = data.get("signals") or []
            parsed: List[SignalPrediction] = []
            for sig in signals:
                token = str(sig.get("token") or "").strip().upper()
                if not token:
                    continue
                stance = str(sig.get("stance") or "hold").lower()
                conf = float(sig.get("confidence") or 0.0)
                conf = max(0.0, min(1.0, conf))
                score = conf if stance == "buy" else (-conf if stance == "sell" else 0.0)
                parsed.append(
                    SignalPrediction(
                        token=token,
                        stance=stance,
                        confidence=conf,
                        sentiment_score=score,
                        source=message.channel,
                        source_type=message.source_type,
                        reason=str(sig.get("reason") or "").strip(),
                        message_excerpt=message.text[:160],
                    )
                )
            return parsed
        except Exception as exc:  # noqa: BLE001
            log.warning("OpenAI sentiment failed (%s); using heuristics.", exc)
            return []

    def suggest_weight_update(self, weights: Dict[str, float], feedback: List[SignalFeedback]) -> Dict[str, float]:
        if not self._client or not feedback:
            return {}
        serialized_feedback = [
            {"source_type": fb.source_type, "pnl": fb.realized_pnl, "notional": fb.notional} for fb in feedback
        ]
        try:
            resp = self._client.chat.completions.create(  # type: ignore[attr-defined]
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "Given per-source PnL feedback, propose updated reliability weights between 0.2 and 3.0. "
                            "Respond with a JSON object {\"weights\": {\"source\": weight, ...}}. "
                            "Prefer to increase weight for consistently positive pnl / notional and decrease otherwise."
                        ),
                    },
                    {
                        "role": "user",
                        "content": json.dumps(
                            {"current_weights": weights, "feedback": serialized_feedback}, ensure_ascii=True
                        ),
                    },
                ],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=300,
            )
            raw = resp.choices[0].message.content or "{}"  # type: ignore[index]
            data = json.loads(raw)
            return data.get("weights") or {}
        except Exception as exc:  # noqa: BLE001
            log.debug("OpenAI weight update suggestion failed (%s).", exc)
            return {}


class ReliabilityLearner:
    """
    Simple bandit-style learner that updates per-source weights using rewards.
    """

    def __init__(
        self,
        base_weight: float = 1.0,
        alpha: float = 0.25,
        decay: float = 0.9,
        min_weight: float = 0.2,
        max_weight: float = 3.0,
        initial_weights: Optional[Dict[str, float]] = None,
    ):
        self.base_weight = base_weight
        self.alpha = alpha
        self.decay = decay
        self.min_weight = min_weight
        self.max_weight = max_weight
        self.weights: Dict[str, float] = initial_weights.copy() if initial_weights else {}

    def aggregate(self, signals: List[SignalPrediction]) -> List[Dict[str, Any]]:
        token_scores: Dict[str, Dict[str, Any]] = {}
        for sig in signals:
            w = self.weights.get(sig.source_type, self.base_weight)
            sig.weight = w
            signed = sig.sentiment_score * w
            bucket = token_scores.setdefault(
                sig.token,
                {"score": 0.0, "sources": set(), "n_signals": 0},
            )
            bucket["score"] += signed
            bucket["n_signals"] += 1
            bucket["sources"].add(sig.source_type)

        aggregated: List[Dict[str, Any]] = []
        for token, bucket in token_scores.items():
            score = bucket["score"]
            action = "buy" if score > 0 else ("sell" if score < 0 else "hold")
            aggregated.append(
                {
                    "token": token,
                    "score": float(score),
                    "action": action,
                    "source_count": bucket["n_signals"],
                    "sources": sorted(bucket["sources"]),
                }
            )
        aggregated.sort(key=lambda x: abs(x["score"]), reverse=True)
        return aggregated

    def apply_feedback(
        self,
        feedback: List[SignalFeedback],
        openai_client: Optional[OpenAISentimentClient] = None,
    ) -> Dict[str, float]:
        for fb in feedback:
            reward = fb.realized_pnl / max(fb.notional, 1e-6)
            reward = max(-1.0, min(1.0, reward))
            current = self.weights.get(fb.source_type, self.base_weight)
            updated = current * self.decay + self.alpha * reward
            clipped = max(self.min_weight, min(self.max_weight, updated))
            self.weights[fb.source_type] = clipped

        if openai_client:
            suggestions = openai_client.suggest_weight_update(self.weights, feedback)
            for source, weight in suggestions.items():
                try:
                    w = float(weight)
                    self.weights[source] = max(self.min_weight, min(self.max_weight, w))
                except Exception:
                    continue
        return self.weights


class TelegramSignalPipeline:
    """End-to-end pipeline: scrape -> sentiment -> RL weighting -> trading signals."""

    def __init__(
        self,
        fetcher: Optional[TelegramScraperAdapter] = None,
        sentiment_client: Optional[OpenAISentimentClient] = None,
        learner: Optional[ReliabilityLearner] = None,
    ):
        self.fetcher = fetcher or TelegramScraperAdapter()
        self.sentiment_client = sentiment_client or OpenAISentimentClient()
        self.learner = learner or ReliabilityLearner()

    def run(
        self,
        channels: Iterable[str],
        limit: int = 200,
        preloaded_messages: Optional[List[TelegramMessage]] = None,
        feedback: Optional[List[SignalFeedback]] = None,
    ) -> Dict[str, Any]:
        messages = preloaded_messages or self.fetcher.fetch_messages(channels, limit=limit)
        all_signals: List[SignalPrediction] = []
        for msg in messages:
            all_signals.extend(self.sentiment_client.analyze(msg))

        aggregated = self.learner.aggregate(all_signals)
        if feedback:
            self.learner.apply_feedback(feedback, openai_client=self.sentiment_client)

        return {
            "messages": messages,
            "signals": all_signals,
            "aggregated": aggregated,
            "weights": self.learner.weights,
        }


def build_feedback_from_pnl(source_type: str, pnl: float, notional: float = 1.0) -> SignalFeedback:
    return SignalFeedback(source_type=source_type, realized_pnl=pnl, notional=notional)
